---
title: 'Online Non-Convex Learning: Following the Perturbed Leader is Optimal'
abstract: We study the problem of online learning with non-convex losses, where the
  learner has access to an offline optimization oracle. We show that the classical
  Follow the Perturbed Leader (FTPL) algorithm achieves optimal regret rate of $O(T^{-1/2})$
  in this setting. This improves upon the previous best-known regret rate of $O(T^{-1/3})$
  for FTPL. We further show that an optimistic variant of FTPL achieves better regret
  bounds when the sequence of losses encountered by the learner is “predictable”.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: suggala20a
month: 0
tex_title: 'Online Non-Convex Learning: Following the Perturbed Leader is Optimal'
firstpage: 845
lastpage: 861
page: 845-861
order: 845
cycles: false
bibtex_author: Suggala, Arun Sai and Netrapalli, Praneeth
author:
- given: Arun Sai
  family: Suggala
- given: Praneeth
  family: Netrapalli
date: 2020-01-28
address: 
publisher: PMLR
container-title: Proceedings of the 31st International Conference  on Algorithmic
  Learning Theory
volume: '117'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 1
  - 28
pdf: http://proceedings.mlr.press/v117/suggala20a/suggala20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
