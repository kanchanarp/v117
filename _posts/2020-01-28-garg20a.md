---
title: Adversarially Robust Learning Could Leverage Computational Hardness.
abstract: Over recent years, devising classification algorithms that are robust to
  adversarial perturbations has emerged as a challenging problem. In particular, deep
  neural nets (DNNs) seem to be susceptible to small imperceptible changes over test
  instances. However, the line of work in <em>provable</em> robustness, so far, has
  been focused on <em>information theoretic</em> robustness, ruling out even the <em>existence</em>
  of any adversarial examples. In this work, we study whether there is a hope to benefit
  from <em>algorithmic</em> nature of an attacker that searches for adversarial examples,
  and ask whether there is <em>any</em>  learning task for which it is possible to
  design classifiers that are only robust against <em>polynomial-time</em> adversaries.
  Indeed, numerous cryptographic tasks (e.g. encryption of long messages) can only
  be secure against computationally bounded adversaries, and are indeed <em>impossible</em>
  for computationally unbounded attackers. Thus, it is natural to ask if the same
  strategy could help robust learning. We show that computational limitation of attackers
  can indeed be useful in robust learning by demonstrating the possibility of a classifier
  for some learning task  for which computational and information theoretic adversaries
  of bounded perturbations have very different power. Namely, while computationally
  unbounded adversaries can attack successfully and find adversarial examples with
  small perturbation, polynomial time adversaries are unable to do so   unless they
  can break standard cryptographic hardness assumptions.  Our results, therefore,
  indicate that perhaps a similar approach to cryptography (relying on computational
  hardness) holds promise for achieving computationally robust machine learning.  On
  the reverse directions, we also show that the existence of such learning task in
  which computational robustness beats information theoretic robustness requires computational
  hardness by implying (average-case) hardness of NP.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: garg20a
month: 0
tex_title: Adversarially Robust Learning Could Leverage Computational Hardness.
firstpage: 364
lastpage: 385
page: 364-385
order: 364
cycles: false
bibtex_author: Garg, Sanjam and Jha, Somesh and Mahloujifar, Saeed and Mohammad, Mahmoody
author:
- given: Sanjam
  family: Garg
- given: Somesh
  family: Jha
- given: Saeed
  family: Mahloujifar
- given: Mahmoody
  family: Mohammad
date: 2020-01-28
address: 
publisher: PMLR
container-title: Proceedings of the 31st International Conference  on Algorithmic
  Learning Theory
volume: '117'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 1
  - 28
pdf: http://proceedings.mlr.press/v117/garg20a/garg20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
