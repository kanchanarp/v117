---
title: On Learning Causal Structures from Non-Experimental Data without Any Faithfulness
  Assumption
abstract: 'Consider the problem of learning, from non-experimental data, the causal
  (Markov equivalence) structure of the true, unknown causal Bayesian network (CBN)
  on a given, fixed set of (categorical) variables. This learning problem is known
  to be very hard, so much so that there is no learning algorithm that converges to
  the truth for all possible CBNs (on the given set of variables). So the convergence
  property has to be sacrificed for some CBNs—but for which? In response, the standard
  practice has been to design and employ learning algorithms that secure the convergence
  property for at least all the CBNs that satisfy the famous <em>faithfulness</em>
  condition, which implies sacrificing the convergence property for some CBNs that
  violate the faithfulness condition (Spirtes, Glymour, and Scheines, 2000). This
  standard design practice can be justified by assuming—that is, accepting on faith—that
  the true, unknown CBN satisfies the faithfulness condition. But the real question
  is this: Is it possible to explain, <em>without assuming</em> the faithfulness condition
  or any of its weaker variants, why it is mandatory rather than optional to follow
  the standard design practice? This paper aims to answer the above question in the
  affirmative. We first define an array of modes of convergence to the truth as desiderata
  that might or might not be achieved by a causal learning algorithm. Those modes
  of convergence concern (i) how pervasive the domain of convergence is on the space
  of all possible CBNs and (ii) how uniformly the convergence happens. Then we prove
  a result to the following effect: for <em>any</em> learning algorithm that tackles
  the causal learning problem in question, if it achieves the best achievable mode
  of convergence (considered in this paper), then it <em>must</em> follow the standard
  design practice of converging to the truth for at least all CBNs that satisfy the
  faithfulness condition—it is a requirement, not an option.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lin20a
month: 0
tex_title: On Learning Causal Structures from Non-Experimental Data without Any Faithfulness
  Assumption
firstpage: 554
lastpage: 582
page: 554-582
order: 554
cycles: false
bibtex_author: Lin, Hanti and Zhang, Jiji
author:
- given: Hanti
  family: Lin
- given: Jiji
  family: Zhang
date: 2020-01-28
address: 
publisher: PMLR
container-title: Proceedings of the 31st International Conference  on Algorithmic
  Learning Theory
volume: '117'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 1
  - 28
pdf: http://proceedings.mlr.press/v117/lin20a/lin20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
