---
title: Solving Bernoulli Rank-One Bandits with Unimodal Thompson Sampling
abstract: "<em>Stochastic Rank-One Bandits</em> are a simple framework for regret
  minimization problems over rank-one matrices of arms. The initially proposed algorithms
  are proved to have logarithmic regret, but do not match the existing lower bound
  for this problem. We close this gap by first proving that rank-one bandits are a
  particular instance of unimodal bandits, and then providing a new analysis of  Unimodal
  Thompson Sampling (UTS). We prove an asymptotically optimal regret bound on the
  frequentist regret of UTS and we support our claims with simulations showing the
  significant improvement of our method compared to the state-of-the-art."
layout: inproceedings
series: Proceedings of Machine Learning Research
id: trinh20a
month: 0
tex_title: Solving Bernoulli Rank-One Bandits with Unimodal Thompson Sampling
firstpage: 862
lastpage: 889
page: 862-889
order: 862
cycles: false
bibtex_author: Trinh, Cindy and Kaufmann, Emilie and Vernade, Claire and Combes, Richard
author:
- given: Cindy
  family: Trinh
- given: Emilie
  family: Kaufmann
- given: Claire
  family: Vernade
- given: Richard
  family: Combes
date: 2020-01-28
address: 
publisher: PMLR
container-title: Proceedings of the 31st International Conference  on Algorithmic
  Learning Theory
volume: '117'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 1
  - 28
pdf: http://proceedings.mlr.press/v117/trinh20a/trinh20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
